apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: prom
  namespace: monitoring
spec:
  chart:
    repository: https://prometheus-community.github.io/helm-charts
    name: kube-prometheus-stack
    version: 9.4.10
  valuesFrom:
    - secretKeyRef:
        name: prom-operator-values
        namespace: monitoring
        key: values.yaml
        optional: false
  values:
    alertmanager:
      ingress:
        enabled: true
        annotations:
          traefik.ingress.kubernetes.io/router.middlewares: system-cf-access-auth@kubernetescrd
        hosts:
          - alertmanager.k8s.nickysemenza.com
    grafana:
      sidecar:
        dashboards:
          enabled: true
          label: grafana_datasource
          searchNamespace: ALL
      ingress:
        enabled: true
        annotations:
          traefik.ingress.kubernetes.io/router.middlewares: system-cf-access-auth@kubernetescrd
        hosts:
          - grafana.k8s.nickysemenza.com
      grafana.ini:
        users:
          allow_sign_up: "false"
          auto_assign_org: "true"
          auto_assign_org_role: "Editor"
        auth:
          proxy:
            enabled: "true"
            header_name: "Cf-Access-Authenticated-User-Email"
            header_property: "email"
            auto_sign_up: "true"

      envValueFrom:
        GF_DATABASE_PASSWORD:
          secretKeyRef:
            name: grafana-db-credentials
            key: db-password
      env:
        GF_TRACING_JAEGER_ADDRESS: "jaeger-tracing-agent.default.svc.cluster.local:6831"
        GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource,jdbranham-diagram-panel,grafana-piechart-panel,natel-discrete-panel"
        GF_DATABASE_TYPE: postgres
        GF_DATABASE_NAME: "grafana-k8s"
        GF_DATABASE_HOST: "34.66.204.3"
        GF_DATABASE_USER: "postgres"
        GF_DATABASE_SSL_MODE: disable
      nodeSelector:
        location: cloud
      plugins:
        - natel-discrete-panel
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: "default"
              orgId: 1
              folder: ""
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/default
      dashboards:
        default:
          # https://github.com/k8s-at-home/k8s-cluster/blob/master/cluster/monitoring/prometheus-operator/prometheus-operator.yaml#L100
          flux:
            url: https://raw.githubusercontent.com/fluxcd/helm-operator/master/chart/helm-operator/dashboards/helm-operator-dashboard.json
            datasource: Prometheus
          vmware-cluster:
            url: https://raw.githubusercontent.com/pryorda/vmware_exporter/master/dashboards/cluster.json
            datasource: Prometheus
          vmware-esx:
            url: https://raw.githubusercontent.com/pryorda/vmware_exporter/master/dashboards/esx.json
            datasource: Prometheus
          vmware-esxi:
            url: https://raw.githubusercontent.com/pryorda/vmware_exporter/master/dashboards/esxi.json
            datasource: Prometheus
          vmware-virtualmachine:
            url: https://raw.githubusercontent.com/pryorda/vmware_exporter/master/dashboards/virtualmachine.json
            datasource: Prometheus
          # curl -s  'https://grafana.com/api/dashboards?orderBy=name&direction=asc&includeLogo=1&page=1&pageSize=100&dataSourceSlugIn=prometheus&filter=unifi-poller' | \
          # jq '.items[] as $item | {slug: $item.slug, revision: $item.revision, gnetId: $item.id}'
          unifi-poller-client-dpi:
            revision: 4
            gnetId: 11310
            datasource: Prometheus
          unifi-poller-client-insights:
            revision: 8
            gnetId: 11315
            datasource: Prometheus
          unifi-poller-network-sites:
            revision: 4
            gnetId: 11311
            datasource: Prometheus
          unifi-poller-uap-insights:
            revision: 9
            gnetId: 11314
            datasource: Prometheus
          unifi-poller-usg-insights:
            revision: 8
            gnetId: 11313
            datasource: Prometheus
          unifi-poller-usw-insights:
            revision: 8
            gnetId: 11312
            datasource: Prometheus
          go-processes:
            revision: 2
            gnetId: 6671
            datasource: Prometheus
          transmission:
            revision: 1
            gnetId: 8259
            datasource: Prometheus
          vmware-stats:
            revision: 1
            gnetId: 11243
            datasource: Prometheus
          node-exporter-server-metrics:
            revision: 8
            gnetId: 405
            datasource: Prometheus
          node-exporter-full:
            revision: 20
            gnetId: 1860
            datasource: Prometheus
          netdata:
            revision: 1
            gnetId: 7107
            datasource: Prometheus
    prometheusOperator:
      prometheusConfigReloaderImage:
        # https://quay.io/repository/coreos/prometheus-config-reloader?tag=v0.20.0&tab=tags
        tag: v0.39.0
      nodeSelector:
        location: cloud
      image:
        repository: raspbernetes/prometheus-operator
    prometheus-node-exporter:
      tolerations:
        - key: "arm"
          operator: "Exists"
    prometheus:
      ingress:
        enabled: true
        annotations:
          traefik.ingress.kubernetes.io/router.middlewares: system-cf-access-auth@kubernetescrd
        hosts:
          - prometheus.k8s.nickysemenza.com
      prometheusSpec:
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        additionalScrapeConfigs:
          - job_name: "netdata-scrape"
            metrics_path: "/api/v1/allmetrics"
            params:
              # format: prometheus | prometheus_all_hosts
              # You can use `prometheus_all_hosts` if you want Prometheus to set the `instance` to your hostname instead of IP
              format: [prometheus]
            honor_labels: true
            static_configs:
              - targets:
                  - 10.0.0.11:19999
      additionalPodMonitors:
        - name: traefik-pod-monitor
          podMetricsEndpoints:
            - port: traefik
              path: /metrics
              interval: 15s
          selector:
            matchLabels:
              app: svclb-system-traefik
          namespaceSelector:
            matchNames:
              - system
        - name: traefik-pod-monitor2
          podMetricsEndpoints:
            - port: traefik
              path: /metrics
              interval: 15s
          selector:
            matchLabels:
              app.kubernetes.io/instance: system-traefik
          namespaceSelector:
            matchNames:
              - system
      additionalServiceMonitors:
        - name: kured
          namespaceSelector:
            matchNames:
              - system
          selector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - kured
          endpoints:
            - port: metrics
              interval: 15s
        - name: digitalocean-exporter
          namespaceSelector:
            matchNames:
              - exporters
          selector:
            matchExpressions:
              - {
                  key: app.kubernetes.io/name,
                  operator: In,
                  values: ["digitalocean-exporter"],
                }
          endpoints:
            - port: http
              interval: 60s
        - name: cloudflare-exporter
          namespaceSelector:
            matchNames:
              - exporters
          selector:
            matchLabels:
              app.kubernetes.io/name: cloudflare-exporter
          endpoints:
            - port: http
        - name: unifi-poller
          namespaceSelector:
            matchNames:
              - exporters
          selector:
            matchLabels:
              app.kubernetes.io/name: unifi-poller
          endpoints:
            - port: http
    kubeControllerManager:
      enabled: false
    kubeEtcd:
      enabled: false
    kubeProxy:
      enabled: false
    kubeScheduler:
      enabled: false
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: karma
  namespace: monitoring
spec:
  chart:
    repository: https://kubernetes-charts.storage.googleapis.com
    name: karma
    version: 1.5.2
  values:
    ingress:
      enabled: true
      annotations:
        traefik.ingress.kubernetes.io/router.middlewares: system-cf-access-auth@kubernetescrd
      hosts:
        - karma.k8s.nickysemenza.com
    env:
      - name: ALERTMANAGER_URI
        value: http://monitoring-prom-prometheus-alertmanager.monitoring.svc.cluster.local:9093
---
# note: set synology snmp v2 community string to `public`
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: snmp
  namespace: monitoring
spec:
  chart:
    repository: https://prometheus-community.github.io/helm-charts
    name: prometheus-snmp-exporter
    version: 0.0.6
  values:
    ingress:
      enabled: true
      annotations:
        traefik.ingress.kubernetes.io/router.middlewares: system-cf-access-auth@kubernetescrd
      hosts:
        - snmp.k8s.nickysemenza.com
    serviceMonitor:
      enabled: true
      params:
        enabled: true
        conf:
          module:
            - synology
          target:
            - 10.0.0.206
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: "snmp-synology-cantaloupe"
  namespace: monitoring
spec:
  endpoints:
    - honorLabels: true
      params:
        module:
          - synology
        target:
          - cantaloupe.lan.nickysemenza.com
      path: /snmp
      port: http
      scrapeTimeout: 10s
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus-snmp-exporter
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: "snmp-synology-files"
  namespace: monitoring
spec:
  endpoints:
    - honorLabels: true
      params:
        module:
          - synology
        target:
          - synology-files.ts.nickysemenza.com
      path: /snmp
      port: http
      scrapeTimeout: 10s
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus-snmp-exporter
